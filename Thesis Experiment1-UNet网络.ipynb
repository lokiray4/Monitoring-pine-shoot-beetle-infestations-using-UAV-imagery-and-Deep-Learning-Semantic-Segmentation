{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55724fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b48c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder 部分（下采样）\n",
    "        self.encoder1 = self.conv_block(3, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bottom 部分（最底层）\n",
    "        self.bottom = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder 部分（上采样）\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # 最后一层，用于输出分割结果\n",
    "        self.output_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"卷积块：包含两层卷积，每层卷积后跟一个 BatchNorm 和 ReLU 激活\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 编码器部分\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(nn.MaxPool2d(2)(enc1))\n",
    "        enc3 = self.encoder3(nn.MaxPool2d(2)(enc2))\n",
    "        enc4 = self.encoder4(nn.MaxPool2d(2)(enc3))\n",
    "        \n",
    "        # Bottom\n",
    "        bottom = self.bottom(nn.MaxPool2d(2)(enc4))\n",
    "        \n",
    "        # 解码器部分 + 跳跃连接\n",
    "        dec4 = self.upconv4(bottom)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)  # 跳跃连接\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        # 输出层\n",
    "        output = self.output_conv(dec1)\n",
    "        output = torch.sigmoid(output)  # 将输出映射到 [0,1] 区间\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7cc27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.7891, Train Acc: 0.1039, Val Loss: 0.8125, Val Acc: 0.0954, Precision: 0.0954, Recall: 1.0000, F1 Score: 0.1711, IoU: 0.0954, mIoU: 0.0954\n",
      "Epoch [2/20], Train Loss: 0.7804, Train Acc: 0.1037, Val Loss: 0.7948, Val Acc: 0.0954, Precision: 0.0954, Recall: 1.0000, F1 Score: 0.1711, IoU: 0.0954, mIoU: 0.0954\n",
      "Epoch [3/20], Train Loss: 0.7761, Train Acc: 0.1046, Val Loss: 0.8014, Val Acc: 0.0954, Precision: 0.0954, Recall: 1.0000, F1 Score: 0.1711, IoU: 0.0954, mIoU: 0.0954\n",
      "Epoch [4/20], Train Loss: 0.7791, Train Acc: 0.1031, Val Loss: 0.7955, Val Acc: 0.0954, Precision: 0.0954, Recall: 1.0000, F1 Score: 0.1711, IoU: 0.0954, mIoU: 0.0954\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "\n",
    "# 自定义数据集类\n",
    "class ContrailDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        super().__init__()\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.files = [f for f in self.image_dir.iterdir() if f.is_file() and f.suffix in ['.png', '.jpg', '.jpeg']]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.files[idx]\n",
    "        mask_path = self.mask_dir / image_path.name\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')  # 读取为RGB图像\n",
    "        mask = Image.open(mask_path).convert('L')  # 读取为灰度图像\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = transforms.ToTensor()(mask)\n",
    "\n",
    "        mask = (mask > 0).float()  # 将掩码二值化\n",
    "        return image, mask.unsqueeze(0)  # 在channel维度增加一个维度\n",
    "\n",
    "# 定义Dice损失函数\n",
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "# 计算 Precision, Recall, F1 Score, IoU\n",
    "def calculate_metrics(preds, labels):\n",
    "    preds = (torch.sigmoid(preds) > 0.5).cpu().numpy().flatten()  # 二值化预测\n",
    "    labels = labels.cpu().numpy().flatten()\n",
    "\n",
    "    precision = precision_score(labels, preds, zero_division=1)\n",
    "    recall = recall_score(labels, preds, zero_division=1)\n",
    "    f1 = f1_score(labels, preds, zero_division=1)\n",
    "    iou = jaccard_score(labels, preds, zero_division=1)\n",
    "\n",
    "    return precision, recall, f1, iou\n",
    "\n",
    "# 计算平均 IoU（mIoU），对于二分类问题，mIoU 就是 IoU 本身\n",
    "def calculate_mIoU(preds, labels):\n",
    "    preds = (torch.sigmoid(preds) > 0.5).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    ious = []\n",
    "    for i in range(preds.shape[0]):  # 针对每一张图片\n",
    "        iou = jaccard_score(labels[i].flatten(), preds[i].flatten(), zero_division=1)\n",
    "        ious.append(iou)\n",
    "    \n",
    "    return sum(ious) / len(ious)\n",
    "\n",
    "def calculate_accuracy(preds, labels):\n",
    "    # 使用Sigmoid并将输出二值化\n",
    "    preds = (torch.sigmoid(preds) > 0.5).float()  # 二值化预测\n",
    "    # 确保预测和标签维度一致\n",
    "    preds = preds.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    # 计算正确的预测像素总数\n",
    "    correct = (preds == labels).sum().item()\n",
    "    # 计算总像素数\n",
    "    total = labels.size(0)\n",
    "\n",
    "    # 返回准确率\n",
    "    acc = correct / total\n",
    "    return acc\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, valid_loader, loss_fn, optimizer, num_epochs, device):\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        # Training phase\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            acc = calculate_accuracy(outputs, masks)\n",
    "            train_acc += acc\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_precision = 0\n",
    "        valid_recall = 0\n",
    "        valid_f1 = 0\n",
    "        valid_iou = 0\n",
    "        valid_miou = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in valid_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = loss_fn(outputs, masks)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                acc = calculate_accuracy(outputs, masks)\n",
    "                valid_acc += acc\n",
    "\n",
    "                precision, recall, f1, iou = calculate_metrics(outputs, masks)\n",
    "                valid_precision += precision\n",
    "                valid_recall += recall\n",
    "                valid_f1 += f1\n",
    "                valid_iou += iou\n",
    "                valid_miou += calculate_mIoU(outputs, masks)\n",
    "\n",
    "        # 平均值\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_acc = train_acc / len(train_loader)\n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "        avg_valid_acc = valid_acc / len(valid_loader)\n",
    "        avg_valid_precision = valid_precision / len(valid_loader)\n",
    "        avg_valid_recall = valid_recall / len(valid_loader)\n",
    "        avg_valid_f1 = valid_f1 / len(valid_loader)\n",
    "        avg_valid_iou = valid_iou / len(valid_loader)\n",
    "        avg_valid_miou = valid_miou / len(valid_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}, '\n",
    "              f'Val Loss: {avg_valid_loss:.4f}, Val Acc: {avg_valid_acc:.4f}, '\n",
    "              f'Precision: {avg_valid_precision:.4f}, Recall: {avg_valid_recall:.4f}, '\n",
    "              f'F1 Score: {avg_valid_f1:.4f}, IoU: {avg_valid_iou:.4f}, mIoU: {avg_valid_miou:.4f}')\n",
    "\n",
    "        # 保存最好的模型\n",
    "        if avg_valid_f1 > best_f1:\n",
    "            best_f1 = avg_valid_f1\n",
    "            torch.save(model.state_dict(), 'UNet1_model.pth')\n",
    "\n",
    "# 设置参数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_dir = '/Users/camus/Desktop/trainX/image'\n",
    "mask_dir = '/Users/camus/Desktop/trainX/maskimage'\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 20\n",
    "\n",
    "# 图像预处理，直接使用256x256的尺寸\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 将图像调整为256x256\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "dataset = ContrailDataset(image_dir, mask_dir, transform=transform)\n",
    "train_size = int(0.75 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "# 初始化模型和损失函数\n",
    "model = UNet().to(device)\n",
    "loss_fn = DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "train_model(model, train_loader, valid_loader, loss_fn, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57536d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1b61dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from UNet_model.pth\n",
      "Epoch [1/42], Train Loss: 0.8089, Train Acc: 0.1068, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [2/42], Train Loss: 0.8089, Train Acc: 0.1069, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [3/42], Train Loss: 0.8101, Train Acc: 0.1064, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [4/42], Train Loss: 0.8092, Train Acc: 0.1067, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [5/42], Train Loss: 0.8103, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [6/42], Train Loss: 0.8085, Train Acc: 0.1071, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [7/42], Train Loss: 0.8110, Train Acc: 0.1061, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [8/42], Train Loss: 0.8108, Train Acc: 0.1059, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [9/42], Train Loss: 0.8101, Train Acc: 0.1067, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [10/42], Train Loss: 0.8116, Train Acc: 0.1054, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [11/42], Train Loss: 0.8088, Train Acc: 0.1069, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [12/42], Train Loss: 0.8071, Train Acc: 0.1083, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [13/42], Train Loss: 0.8095, Train Acc: 0.1070, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [14/42], Train Loss: 0.8071, Train Acc: 0.1078, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [15/42], Train Loss: 0.8106, Train Acc: 0.1058, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [16/42], Train Loss: 0.8082, Train Acc: 0.1072, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [17/42], Train Loss: 0.8112, Train Acc: 0.1056, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [18/42], Train Loss: 0.8083, Train Acc: 0.1073, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [19/42], Train Loss: 0.8122, Train Acc: 0.1055, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [20/42], Train Loss: 0.8095, Train Acc: 0.1064, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [21/42], Train Loss: 0.8104, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [22/42], Train Loss: 0.8054, Train Acc: 0.1097, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [23/42], Train Loss: 0.8085, Train Acc: 0.1072, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [24/42], Train Loss: 0.8101, Train Acc: 0.1061, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [25/42], Train Loss: 0.8112, Train Acc: 0.1054, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [26/42], Train Loss: 0.8115, Train Acc: 0.1053, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [27/42], Train Loss: 0.8107, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [28/42], Train Loss: 0.8103, Train Acc: 0.1061, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [29/42], Train Loss: 0.8071, Train Acc: 0.1083, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [30/42], Train Loss: 0.8103, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [31/42], Train Loss: 0.8097, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [32/42], Train Loss: 0.8107, Train Acc: 0.1064, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [33/42], Train Loss: 0.8091, Train Acc: 0.1062, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [34/42], Train Loss: 0.8090, Train Acc: 0.1069, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [35/42], Train Loss: 0.8079, Train Acc: 0.1080, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [36/42], Train Loss: 0.8078, Train Acc: 0.1079, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [37/42], Train Loss: 0.8104, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [38/42], Train Loss: 0.8116, Train Acc: 0.1056, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [39/42], Train Loss: 0.8110, Train Acc: 0.1055, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [40/42], Train Loss: 0.8103, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [41/42], Train Loss: 0.8097, Train Acc: 0.1060, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n",
      "Epoch [42/42], Train Loss: 0.8086, Train Acc: 0.1071, Val Loss: 0.8181, Val Acc: 0.1017, Precision: 0.1017, Recall: 1.0000, F1 Score: 0.1819, IoU: 0.1017, mIoU: 0.1017\n"
     ]
    }
   ],
   "source": [
    "# 定义完整的U-Net模型\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Contracting Path (Encoder)\n",
    "        self.encoder1 = self.conv_block(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Expansive Path (Decoder)\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self.conv_block(1024, 512)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self.conv_block(512, 256)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.conv_final = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Contracting path (Encoder)\n",
    "        e1 = self.encoder1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        \n",
    "        e2 = self.encoder2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        \n",
    "        e3 = self.encoder3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "        \n",
    "        e4 = self.encoder4(p3)\n",
    "        p4 = self.pool4(e4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p4)\n",
    "        \n",
    "        # Expansive path (Decoder)\n",
    "        u4 = self.upconv4(b)\n",
    "        d4 = torch.cat((u4, e4), dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "        \n",
    "        u3 = self.upconv3(d4)\n",
    "        d3 = torch.cat((u3, e3), dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "        \n",
    "        u2 = self.upconv2(d3)\n",
    "        d2 = torch.cat((u2, e2), dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "        \n",
    "        u1 = self.upconv1(d2)\n",
    "        d1 = torch.cat((u1, e1), dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.conv_final(d1)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 设置参数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_dir = '/Users/camus/Desktop/trainX2/image'\n",
    "mask_dir = '/Users/camus/Desktop/trainX2/maskimage'\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 42\n",
    "\n",
    "# 图像预处理，直接使用256x256的尺寸\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 将图像调整为256x256\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# 加载数据集\n",
    "dataset = ContrailDataset(image_dir, mask_dir, transform=transform)\n",
    "train_size = int(0.75 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "# 继续模型训练\n",
    "\n",
    "# 初始化模型和损失函数\n",
    "model = UNet().to(device)\n",
    "loss_fn = DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 继续训练前，加载模型的权重\n",
    "checkpoint_path = 'UNet_model.pth'\n",
    "if Path(checkpoint_path).exists():\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(\"Model loaded from\", checkpoint_path)\n",
    "else:\n",
    "    print(\"No checkpoint found, training from scratch.\")\n",
    "\n",
    "# 继续训练\n",
    "train_model(model, train_loader, valid_loader, loss_fn, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f8b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
